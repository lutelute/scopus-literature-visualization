#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
combine_scopus_csv.py
---------------------
å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã® *.csvï¼ˆScopus ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼‰ã‚’ 1 æœ¬ã«çµåˆã€‚
æ—¢ã«ç”Ÿæˆæ¸ˆã¿ã® scopus_combined.csv ã¯å¯¾è±¡å¤–ã€‚
é‡è¤‡è¡Œã¯ drop_duplicates ã§é™¤å»ã€‚

ä½¿ç”¨æ–¹æ³•:
1. ä½œæ¥­ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
2. ãã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã«Scopus CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®
3. ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ãƒ³/å®Ÿè¡Œ
"""

import os, glob, pandas as pd

OUT_NAME = "scopus_combined.csv"

def main() -> None:
    # å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæ¥­ãƒ•ã‚©ãƒ«ãƒ€ï¼‰ã§CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    work_dir = os.getcwd()
    print(f"ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {work_dir}")
    
    csvs = [f for f in glob.glob(os.path.join(work_dir, "*.csv"))
            if os.path.basename(f) != OUT_NAME]
    
    print(f"ğŸ” æ¤œå‡ºã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«: {len(csvs)}ä»¶")
    for csv_file in csvs:
        print(f"  - {os.path.basename(csv_file)}")

    if not csvs:
        print("âŒ çµåˆå¯¾è±¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("  1. ä½œæ¥­ãƒ•ã‚©ãƒ«ãƒ€ã«Scopus CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®")
        print("  2. ãã®ä½œæ¥­ãƒ•ã‚©ãƒ«ãƒ€å†…ã§ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ")
        return

    print(f"ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆä¸­...")
    df = pd.concat([pd.read_csv(f, dtype=str) for f in csvs],
                   ignore_index=True).fillna("")
    
    original_count = len(df)
    df.drop_duplicates(inplace=True)   # å®Œå…¨ä¸€è‡´ã‚’å‰Šé™¤
    deduplicated_count = len(df)
    
    output_path = os.path.join(work_dir, OUT_NAME)
    df.to_csv(output_path, index=False)

    print(f"âœ… çµåˆå®Œäº†:")
    print(f"  ğŸ“ å…¥åŠ›: {len(csvs)}ãƒ•ã‚¡ã‚¤ãƒ«")
    print(f"  ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿: {original_count:,}è¡Œ")
    print(f"  ğŸ”„ é‡è¤‡é™¤å»å¾Œ: {deduplicated_count:,}è¡Œ")
    print(f"  ğŸ’¾ å‡ºåŠ›: {OUT_NAME}")
    
    if original_count != deduplicated_count:
        print(f"  âš ï¸  {original_count - deduplicated_count:,}è¡Œã®é‡è¤‡ã‚’é™¤å»")

if __name__ == "__main__":
    main()